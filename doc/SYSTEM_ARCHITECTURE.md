# System Architecture & Pipeline Documentation

## ğŸ“Š Table of Contents
1. [System Overview](#system-overview)
2. [High-Level Architecture Diagram](#high-level-architecture-diagram)
3. [Component Architecture](#component-architecture)
4. [Request/Response Pipeline](#requestresponse-pipeline)
5. [Data Flow Diagrams](#data-flow-diagrams)
6. [Module Interactions](#module-interactions)
7. [Technology Stack](#technology-stack)

---

## ğŸ¯ System Overview

**Organic Fishstick** is a dual-mode AI chatbot system that combines:

1. **RAG (Retrieval-Augmented Generation)** - Context-aware LLM responses from document knowledge
2. **Eligibility Engine** - Rule-based product eligibility checking
3. **Multi-channel UI** - Both Streamlit web UI and FastAPI Portal
4. **Persistent Storage** - SQLite conversation history and audit trails

The system serves banking customers by:
- âœ… Answering product questions with document context
- âœ… Determining product eligibility with evidence-based explanations
- âœ… Maintaining conversation history across sessions
- âœ… Providing audit trails for compliance

---

## ğŸ—ï¸ High-Level Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           USER INTERFACE LAYER                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Streamlit UI    â”‚      FastAPI Portal              â”‚  Raw API Endpoints    â”‚
â”‚  (app.py)        â”‚      (portal_api.py)             â”‚  (REST)               â”‚
â”‚                  â”‚                                  â”‚                       â”‚
â”‚ http://localhost â”‚ http://localhost:8000            â”‚ /api/chat             â”‚
â”‚ :8501            â”‚ /api/conversations              â”‚ /api/eligibility      â”‚
â”‚                  â”‚ /api/messages                   â”‚                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚                           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  BACKEND CHAT FACADE       â”‚
                    â”‚  (backend/chat.py)         â”‚
                    â”‚                            â”‚
                    â”‚ â€¢ Context Building         â”‚
                    â”‚ â€¢ Query Routing            â”‚
                    â”‚ â€¢ Response Formatting      â”‚
                    â”‚ â€¢ Message Persistence      â”‚
                    â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚              â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                                        â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   RAG ENGINE    â”‚            â”‚ ELIGIBILITY ENGINE       â”‚
    â”‚                 â”‚            â”‚                          â”‚
    â”‚ â€¢ Query         â”‚            â”‚ â€¢ Intent Detection       â”‚
    â”‚ â€¢ Retrieve      â”‚            â”‚ â€¢ Account Extraction     â”‚
    â”‚ â€¢ Augment       â”‚            â”‚ â€¢ Account Validation     â”‚
    â”‚ â€¢ Generate      â”‚            â”‚ â€¢ Eligibility Check      â”‚
    â”‚                 â”‚            â”‚ â€¢ Evidence Building      â”‚
    â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚          â”‚                         â”‚
    â”Œâ”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ LLM â”‚  â”‚ VECTOR DB     â”‚     â”‚ DATA LOADER     â”‚
    â”‚     â”‚  â”‚ (Chroma)      â”‚     â”‚ Rules & Config  â”‚
    â”‚Ollama/â”‚ â”œâ”€ Ollama DB  â”‚     â”œâ”€ Playbooks     â”‚
    â”‚Geminiâ”‚ â”œâ”€ Gemini DB  â”‚     â”œâ”€ Eligibility    â”‚
    â”‚     â”‚  â”‚              â”‚     â”‚   Data            â”‚
    â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
             â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚ SOURCE DOCS   â”‚
             â”‚ (rag/data/)   â”‚
             â”‚ â€¢ PDFs        â”‚
             â”‚ â€¢ DOCX        â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              PERSISTENT STORAGE LAYER                      â”‚
    â”‚                                                            â”‚
    â”‚  SQLite Database (organic-fishstick.db)                   â”‚
    â”‚  SQLAlchemy ORM + Alembic Migrations                      â”‚
    â”‚                                                            â”‚
    â”‚  Tables:                                                  â”‚
    â”‚  â”œâ”€ users              [Authentication & Authorization]  â”‚
    â”‚  â”œâ”€ user_sessions      [Active Sessions]                â”‚
    â”‚  â”œâ”€ conversations      [Conversation Threads]           â”‚
    â”‚  â””â”€ messages           [Message History]                â”‚
    â”‚                                                            â”‚
    â”‚  Features:                                                â”‚
    â”‚  â”œâ”€ Multi-conversation Management                         â”‚
    â”‚  â”œâ”€ Message Metadata (tokens, latency, sources)          â”‚
    â”‚  â”œâ”€ Indexing for Fast Queries                            â”‚
    â”‚  â””â”€ Cascade Deletes (conversation â†’ messages)            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚            AUTHENTICATION & SECURITY LAYER                â”‚
    â”‚                                                            â”‚
    â”‚  â”œâ”€ Session Management (auth.session)                    â”‚
    â”‚  â”œâ”€ Password Hashing (auth.password)                     â”‚
    â”‚  â”œâ”€ User Validation (auth.validation)                    â”‚
    â”‚  â”œâ”€ CORS & Middleware                                    â”‚
    â”‚  â””â”€ Request/Response Logging                             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               LOGGING & OBSERVABILITY LAYER               â”‚
    â”‚                                                            â”‚
    â”‚  â”œâ”€ Structured Logging (utils/logger/)                   â”‚
    â”‚  â”œâ”€ Request ID Tracing                                   â”‚
    â”‚  â”œâ”€ Performance Metrics (latency, tokens)                â”‚
    â”‚  â”œâ”€ Error Tracking with Tracebacks                       â”‚
    â”‚  â””â”€ Log Files (logs/*.log)                               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Component Architecture

### **Module Breakdown**

```
â”Œâ”€ RAG Module (rag/)
â”‚  â”œâ”€ populate_database.py      # Load PDFs/DOCX, generate embeddings
â”‚  â”œâ”€ query_data.py             # Retrieve relevant documents
â”‚  â”œâ”€ get_embedding_function.py # Embedding model (Ollama/Gemini)
â”‚  â”œâ”€ get_generation_function.py# Generation model (Ollama/Gemini)
â”‚  â”œâ”€ config/
â”‚  â”‚  â”œâ”€ provider_config.py     # Provider selection & settings
â”‚  â”‚  â”œâ”€ index_registry.py      # DB collections per provider
â”‚  â”‚  â””â”€ prompts.py             # System prompts for LLM
â”‚  â””â”€ chroma/                   # Vector database storage
â”‚     â”œâ”€ ollama/                # Ollama embeddings
â”‚     â””â”€ gemini/                # Gemini embeddings
â”‚
â”œâ”€ Eligibility Module (eligibility/)
â”‚  â”œâ”€ orchestrator.py           # Main orchestrator (singleton)
â”‚  â”œâ”€ intent_detector.py        # Detect eligibility questions
â”‚  â”œâ”€ account_extractor.py      # Extract account numbers
â”‚  â”œâ”€ account_validator.py      # Validate account format
â”‚  â”œâ”€ eligibility_processor.py  # Check eligibility rules
â”‚  â”œâ”€ llm_payload_builder.py    # Format evidence for LLM
â”‚  â”œâ”€ config/                   # Playbooks & rules
â”‚  â”‚  â”œâ”€ reason_playbook.json   # Reason codes & titles
â”‚  â”‚  â”œâ”€ explanation_playbook.json # Evidence display templates
â”‚  â”‚  â””â”€ evidence_display_rules.json # Formatting rules
â”‚  â””â”€ data/                     # Eligibility data
â”‚     â”œâ”€ eligible_customers.xlsx # Eligible account list
â”‚     â””â”€ reasons_file.xlsx       # Reasons per account
â”‚
â”œâ”€ Database Module (database/)
â”‚  â”œâ”€ initialization.py         # DB setup & initialization
â”‚  â”œâ”€ core/
â”‚  â”‚  â”œâ”€ config.py              # Database URL & type
â”‚  â”‚  â”œâ”€ engine.py              # SQLAlchemy engine
â”‚  â”‚  â””â”€ session.py             # Session management
â”‚  â”œâ”€ models/                   # SQLAlchemy ORM models
â”‚  â”‚  â”œâ”€ base.py                # Base model class
â”‚  â”‚  â”œâ”€ user.py                # User authentication
â”‚  â”‚  â”œâ”€ user_session.py        # Active sessions
â”‚  â”‚  â”œâ”€ conversation.py        # Conversation threads
â”‚  â”‚  â””â”€ message.py             # Message history
â”‚  â”œâ”€ repository/               # Data access layer
â”‚  â”œâ”€ services/                 # Business logic
â”‚  â””â”€ migrations/               # Alembic migrations (if used)
â”‚
â”œâ”€ Backend Facade (backend/)
â”‚  â”œâ”€ chat.py                   # Unified chat interface
â”‚  â”‚  â”œâ”€ run_chat() - Main entry point
â”‚  â”‚  â”œâ”€ validate_message()
â”‚  â”‚  â””â”€ Message formatting & persistence
â”‚  â””â”€ Used by: app.py, portal_api.py
â”‚
â”œâ”€ Authentication & Security (auth/)
â”‚  â”œâ”€ __init__.py               # Auth endpoints
â”‚  â”œâ”€ session.py                # Session management
â”‚  â”œâ”€ password.py               # Hashing & validation
â”‚  â”œâ”€ validation.py             # Email & input validation
â”‚  â”œâ”€ user_service.py           # User CRUD operations
â”‚  â”œâ”€ logger.py                 # Auth logging
â”‚  â””â”€ middleware.py             # Custom middleware
â”‚
â”œâ”€ Utilities (utils/)
â”‚  â”œâ”€ logger/                   # Structured logging
â”‚  â”‚  â”œâ”€ rag_logging.py         # RAG logger with request IDs
â”‚  â”‚  â”œâ”€ session_manager.py     # Session tracking
â”‚  â”‚  â””â”€ trace.py               # Technical tracing
â”‚  â”œâ”€ context/                  # Request context
â”‚  â”‚  â””â”€ context_builder.py     # Build conversation context
â”‚  â”œâ”€ commands/                 # Command parsing
â”‚  â”‚  â””â”€ parse_command.py       # CLI-style commands
â”‚  â””â”€ tests/                    # Testing utilities
â”‚
â”œâ”€ User Interfaces
â”‚  â”œâ”€ app.py                    # Streamlit WebUI (port 8501)
â”‚  â”œâ”€ portal_api.py             # FastAPI Portal (port 8000)
â”‚  â””â”€ portal/                   # Portal static files
â”‚     â”œâ”€ index.html
â”‚     â”œâ”€ login.html
â”‚     â””â”€ static/
â”‚
â””â”€ Scripts & Tools
   â”œâ”€ start_portal.sh           # Start Portal with full init
   â”œâ”€ start.sh                  # Start Streamlit
   â”œâ”€ start_dev.sh              # Start both
   â””â”€ scripts/
      â”œâ”€ seed_dev_user.py       # Create dev user
      â”œâ”€ create_admin.py        # Create admin user
      â””â”€ cleanup_sessions.py    # Expired session cleanup
```

---

## ğŸ“¤ğŸ“¥ Request/Response Pipeline

### **User Query to Response (Complete Flow)**

```
STEP 1: USER INPUT
  â†“
  User sends message via Streamlit/Portal UI
  â””â”€ Message: "What products are available for my account 12345?"
  â””â”€ Session: User authenticated, session valid
  â””â”€ Conversation: Loaded from database

STEP 2: VALIDATION
  â†“
  backend/chat.py: validate_message()
  â”œâ”€ Check non-empty
  â”œâ”€ Check length limits
  â”œâ”€ Parse for commands
  â””â”€ Validate command arguments (if command)
  
  âœ“ Invalid â†’ Return error message
  âœ“ Valid â†’ Continue

STEP 3: CONTEXT BUILDING
  â†“
  utils/context/context_builder.py: build_rag_context()
  â”œâ”€ Load conversation history (last N messages)
  â”œâ”€ Format as LLM context
  â””â”€ Create system prompt with guidelines
  â””â”€ Output: Conversation context string

STEP 4: INTENT DETECTION & ROUTING
  â†“
  eligibility/orchestrator.py: process_user_message()
  â”œâ”€ Call intent_detector: Is this an eligibility question?
  â”‚
  â”œâ”€ IF eligibility question (YES):
  â”‚  â”‚  â†“
  â”‚  â”‚  CONTINUE ELIGIBILITY FLOW (see STEP 5A)
  â”‚  â”‚
  â”œâ”€ ELIF command (YES):
  â”‚  â”‚  â†“
  â”‚  â”‚  DISPATCH COMMAND (see STEP 5B)
  â”‚  â”‚
  â””â”€ ELSE (RAG question):
     â””â”€> CONTINUE RAG FLOW (see STEP 5C)

STEP 5A: ELIGIBILITY FLOW (If eligibility question detected)
  â†“
  eligibility/orchestrator.py:
  â”œâ”€ extract_account_numbers() â†’ ["12345678"]
  â”œâ”€ validate_accounts() â†’ âœ“ Valid 10-digit account
  â”œâ”€ check_eligibility() â†’ Check against eligible_customers.xlsx
  â”‚  â”œâ”€ Account found? â†’ Status (ELIGIBLE/INELIGIBLE)
  â”‚  â””â”€ If INELIGIBLE: Load reasons_file.xlsx
  â”œâ”€ build_evidence() â†’ Extract reason codes & evidence
  â”œâ”€ format_for_llm() â†’ Create LLM payload with evidence
  â””â”€ Output: Eligibility result with evidence
     â””â”€> REDIRECT TO LLM WITH EVIDENCE (STEP 6A)

STEP 5B: COMMAND DISPATCH (If command detected)
  â†“
  utils/commands:
  â”œâ”€ parse_command() â†’ Parse CLI-style syntax
  â”œâ”€ validate_command_args() â†’ Validate parameters
  â”œâ”€ dispatch_command() â†’ Execute command handler
  â””â”€ Output: Command result (e.g., conversation list)
     â””â”€> SAVE & RETURN RESULT

STEP 5C: RAG FLOW (If RAG question)
  â†“
  rag/query_data.py: query_rag()
  â”œâ”€ Get embedding function (Ollama/Gemini)
  â”œâ”€ Query Chroma vector database
  â”‚  â”œâ”€ Similarity search with top-k results
  â”‚  â””â”€ Retrieve: ["Document A (page 2)", "Document B (page 5)"]
  â”œâ”€ Extract source metadata
  â”œâ”€ Build context: Source documents + conversation history
  â””â”€ Output: Retrieved documents + sources
     â””â”€> REDIRECT TO LLM WITH CONTEXT (STEP 6C)

STEP 6A: LLM GENERATION (Eligibility with Evidence)
  â†“
  rag/get_generation_function.py:
  â”œâ”€ Provider: ACTIVE_GENERATION_PROVIDER (Ollama/Gemini)
  â”œâ”€ Model: llama3.2:3b (or gemini-2.0-flash)
  â”œâ”€ Prompt: System + context + eligibility evidence
  â”œâ”€ Call LLM: Generate user-friendly response
  â”œâ”€ Streaming: Yield chunks as they arrive
  â””â”€ Output: Full response text
     â””â”€> FORMAT & RETURN (STEP 7)

STEP 6B: LLM GENERATION (Command Result)
  â†“
  Command result already formatted
  â””â”€> FORMAT & RETURN (STEP 7)

STEP 6C: LLM GENERATION (RAG with Sources)
  â†“
  rag/get_generation_function.py:
  â”œâ”€ Provider: ACTIVE_GENERATION_PROVIDER
  â”œâ”€ Model: llama3.2:3b (or gemini-2.0-flash)
  â”œâ”€ Prompt: System + conversation + retrieved docs
  â”œâ”€ Call LLM: Generate grounded response
  â”œâ”€ Streaming: Yield chunks as they arrive
  â””â”€ Output: Full response text
     â””â”€> FORMAT & RETURN (STEP 7)

STEP 7: RESPONSE FORMATTING & PERSISTENCE
  â†“
  backend/chat.py:
  â”œâ”€ Get final response from LLM
  â”œâ”€ Extract metadata:
  â”‚  â”œâ”€ Tokens used
  â”‚  â”œâ”€ Latency (ms)
  â”‚  â”œâ”€ Model name
  â”‚  â”œâ”€ Source documents (if RAG)
  â”‚  â””â”€ Request ID for tracing
  â”œâ”€ Create Message object (ASSISTANT role)
  â””â”€ Output: Formatted message with metadata

STEP 8: PERSISTENCE
  â†“
  database/repository/message_repository.py:
  â”œâ”€ Save USER message to database
  â”œâ”€ Save ASSISTANT message to database
  â”œâ”€ Update conversation.message_count
  â”œâ”€ Update conversation.last_message_at
  â””â”€ Commit transaction

STEP 9: LOGGING
  â†“
  utils/logger/rag_logging.py:
  â”œâ”€ Create structured log entry
  â”œâ”€ Include: request_id, event, severity, metadata
  â”œâ”€ Write to: logs/rag_*.log
  â””â”€ Output: {timestamp} [request_id] Userâ†’Assistant flow complete

STEP 10: RESPONSE TO USER
  â†“
  â”œâ”€ Streamlit: Display in chat widget
  â”œâ”€ Portal: Send JSON response with metadata
  â””â”€ User sees: Response + sources (if RAG) + response time

END
```

---

## ğŸ”— Module Interactions

### **Eligibility + RAG Hybrid Flow**

```
User: "What's the eligibility for account 12345?"

1. Intent Detection finds: account number + eligibility question
   â†“
2. Extract: 12345 â†’ account_number
   â†“
3. Validate: Is "12345" a valid 10-digit account? (Could be 1234500000)
   â†“
4. Check Eligibility:
   â”œâ”€ Look in eligible_customers.xlsx â†’ Found? ELIGIBLE
   â””â”€ Look in reasons_file.xlsx â†’ Get reasons â†’ INELIGIBLE
   â†“
5. Build Evidence:
   â”œâ”€ Reason: "JOINT_ACCOUNT_EXCLUSION"
   â”œâ”€ Detail: "Joint accounts are not eligible"
   â””â”€ Template: "This account is {status} because {reason}. {detail}"
   â†“
6. Call LLM with Evidence:
   â”œâ”€ System: "You are a banking assistant..."
   â”œâ”€ Context: Previous conversation
   â”œâ”€ Evidence: Full eligibility details
   â””â”€ User Query: "What's the eligibility for account 12345?"
   â†“
7. LLM Response:
   "Your account (12345) is currently ineligible for this product 
    because it is a joint account. Joint accounts require additional 
    verification. Please contact customer service at..."
   â†“
8. Save conversation + return response
```

---

## ğŸ’¾ Data Flow Diagrams

### **Data Ingestion (populate_database.py)**

```
SOURCE DOCUMENTS (rag/data/)
  â”œâ”€ document1.pdf
  â”œâ”€ document2.pdf
  â””â”€ document3.docx
       â†“
DOCUMENT LOADER (PyPDFDirectoryLoader, Docx2txtLoader)
       â†“
RAW TEXT EXTRACTION
       â†“
TEXT SPLITTER (RecursiveCharacterTextSplitter)
  â””â”€ Split on: ["\n\n", "\n", " ", ""]
  â””â”€ Chunk size: 1000 tokens
  â””â”€ Overlap: 200 tokens
       â†“
CHUNKS + METADATA
  {
    "content": "chunk text...",
    "metadata": {
      "source": "document1.pdf",
      "page": 5,
      "id": "doc1_chunk_5"
    }
  }
       â†“
EMBEDDING FUNCTION (get_embedding_function)
  â”œâ”€ Provider: ACTIVE_EMBEDDING_PROVIDER
  â”œâ”€ Model: nomic-embed-text (Ollama) OR gemini-embedding-001 (Gemini)
  â””â”€ Dimension: 768
       â†“
EMBEDDINGS (Vector representation)
  [0.234, -0.102, 0.456, ... 768 dimensions]
       â†“
CHROMA VECTOR DATABASE
  â”œâ”€ Collection Name: Based on provider
  â”œâ”€ Path: rag/chroma/ollama/ OR rag/chroma/gemini/
  â””â”€ Storage:
     â”œâ”€ chroma.sqlite3 (metadata)
     â””â”€ data/ (vector data)
```

### **Query Execution (query_data.py)**

```
USER QUERY
  "What are the eligibility requirements?"
       â†“
QUERY EMBEDDING
  â”œâ”€ Provider: ACTIVE_EMBEDDING_PROVIDER
  â”œâ”€ Model: Same as training embeddings
  â””â”€ Output: Query vector [0.210, -0.095, 0.478...]
       â†“
SIMILARITY SEARCH (Chroma)
  â”œâ”€ Distance Metric: Cosine Similarity
  â”œâ”€ Top-K: 5 results
  â””â”€ Results ranked by relevance
       â†“
RETRIEVED DOCUMENTS
  [
    {
      "content": "Eligibility requirements...",
      "score": 0.87,
      "metadata": {"source": "doc1.pdf", "page": 2}
    },
    {
      "content": "Additional requirements...",
      "score": 0.82,
      "metadata": {"source": "doc2.pdf", "page": 1}
    },
    ...
  ]
       â†“
CONTEXT BUILDING
  â”œâ”€ Conversation history (last 5 messages)
  â”œâ”€ Retrieved documents
  â””â”€ System prompt
       â†“
LLM PROMPT
  System: "You are a helpful banking assistant..."
  Context: Previous conversation + retrieved docs
  Query: User's original question
       â†“
LLM GENERATION (Streaming)
  Model generates response token by token
       â†“
RESPONSE TO USER
  + Sources cited from retrieved documents
```

---

## ğŸ› ï¸ Technology Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Frontend** | Streamlit, FastAPI + HTML/CSS/JS | Web UI & API |
| **Backend** | Python 3.8+, FastAPI, Flask-like patterns | Business logic |
| **ORM** | SQLAlchemy | Database abstraction |
| **Database** | SQLite (dev), PostgreSQL (prod) | Persistent storage |
| **Vector DB** | Chroma | Semantic search |
| **Embeddings** | Ollama (nomic-embed-text) or Gemini | Vector generation |
| **LLM** | Ollama (llama3.2:3b) or Gemini (gemini-2.0-flash) | Text generation |
| **Auth** | bcrypt, JWT-style tokens | Security |
| **Logging** | Python logging, custom JSON formatters | Observability |
| **Configuration** | `.env` files, environment variables | Settings management |
| **Testing** | pytest | Quality assurance |

---

## ğŸ”Œ Integration Points

### **External Services**

```
System â†â†’ Ollama Service
  â”œâ”€ Embeddings: http://localhost:11434/api/embed
  â”œâ”€ Chat: http://localhost:11434/api/chat
  â””â”€ Tags: http://localhost:11434/api/tags (health check)

System â†â†’ Google Gemini API
  â”œâ”€ Endpoint: https://generativelanguage.googleapis.com/v1
  â”œâ”€ Auth: GEMINI_API_KEY header
  â””â”€ Models: gemini-embedding-001, gemini-2.0-flash

System â†â†’ File System
  â”œâ”€ Read: rag/data/*.pdf, *.docx
  â”œâ”€ Write: rag/chroma/, logs/
  â””â”€ Access: eligibility/data/*.xlsx
```

---

## ğŸ“ˆ Scalability Considerations

### **Current Architecture Limits**

- **Single File Database**: SQLite suitable for development, ~10k conversations
- **In-Memory Embeddings**: Vector DB queries sequential (Chroma)
- **Synchronous Processing**: LLM calls block until response received

### **Production Scaling Path**

```
Phase 1: Current
  â”œâ”€ SQLite local database
  â”œâ”€ Chroma file-based vector DB
  â””â”€ Single-threaded request handling

Phase 2: Distributed (Recommended)
  â”œâ”€ PostgreSQL Remote Database
  â”œâ”€ Redis for session caching
  â”œâ”€ Chroma in server mode (separate process)
  â””â”€ FastAPI + Uvicorn workers

Phase 3: Cloud-Native
  â”œâ”€ PostgreSQL on RDS/Cloud SQL
  â”œâ”€ Vector DB service (Pinecone/Weaviate)
  â”œâ”€ Kubernetes orchestration
  â””â”€ CDN for static assets
```

---

## ğŸ“š Related Documentation

- [STARTUP_GUIDE.md](STARTUP_GUIDE.md) - Setup & initialization
- [DEVELOPER_GUIDE.md](DEVELOPER_GUIDE.md) - Detailed module documentation
- [DATABASE_GUIDE.md](DATABASE_GUIDE.md) - Database schema & queries
- [QUICK_REFERENCE.md](QUICK_REFERENCE.md) - Quick commands

---

**Last Updated:** February 15, 2026  
**Version:** 1.0  
**Maintained By:** Development Team


